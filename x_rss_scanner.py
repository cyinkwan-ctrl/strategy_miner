#!/usr/bin/env python3
"""
X/Twitter RSS æ‰«æå™¨
ä½¿ç”¨ Nitter ç­‰ç¬¬ä¸‰æ–¹ RSS æœåŠ¡è·å–æ¨æ–‡
é›¶æˆæœ¬ã€æ— éœ€ API Key
"""

import os
import sys
import json
import logging
import feedparser
import re
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import dataclass
import requests
from urllib.parse import urlparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, '/Users/januswing/.openclaw/workspace/strategy_miner')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('x_rss_scanner')

@dataclass
class TweetItem:
    """æ¨æ–‡æ•°æ®"""
    author: str
    url: str
    title: str
    content: str
    published_at: str
    source: str = "rss"

# RSS æœåŠ¡åœ°å€ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
RSS_SERVICES = [
    "https://nitter.net/{username}/rss",
    "https://twitrss.me/user/{username}/rss",
    "https://rss.app/feeds/v1.2/{username}.xml",
]

class XRSSScanner:
    """X/Twitter RSS æ‰«æå™¨"""
    
    def __init__(self, config_file: str = None):
        self.config_file = config_file or '/Users/januswing/.openclaw/workspace/strategy_miner/monitored_accounts.json'
        self.accounts = self._load_accounts()
        
    def _load_accounts(self) -> List[Dict]:
        """åŠ è½½ç›‘æ§è´¦å·é…ç½®"""
        try:
            with open(self.config_file, 'r') as f:
                data = json.load(f)
                return data.get('accounts', [])
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")
            return []
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
            return []
    
    def _get_rss_url(self, username: str) -> str:
        """ç”Ÿæˆ RSS URL"""
        for service in RSS_SERVICES:
            url = service.format(username=username)
            # æ£€æŸ¥æ˜¯å¦æ˜¯ Nitterï¼ˆæœ€å¯é ï¼‰
            if 'nitter.net' in url:
                return url
        return RSS_SERVICES[0].format(username=username)
    
    def check_rss_available(self, username: str) -> bool:
        """æ£€æŸ¥ RSS æºæ˜¯å¦å¯ç”¨"""
        rss_url = self._get_rss_url(username)
        
        try:
            response = requests.get(rss_url, timeout=10)
            if response.status_code == 200 and 'xml' in response.headers.get('content-type', '').lower():
                logger.info(f"âœ… RSS å¯ç”¨: {username} -> {rss_url}")
                return True
            else:
                logger.warning(f"âŒ RSS ä¸å¯ç”¨: {username} (çŠ¶æ€ç : {response.status_code})")
                return False
        except Exception as e:
            logger.error(f"âŒ RSS æ£€æŸ¥å¤±è´¥: {username} - {e}")
            return False
    
    def fetch_feed(self, username: str) -> Optional[feedparser.FeedParserDict]:
        """è·å– RSS è®¢é˜…æº"""
        rss_url = self._get_rss_url(username)
        
        try:
            logger.info(f"è·å– RSS æº: {rss_url}")
            feed = feedparser.parse(rss_url)
            
            if feed.bozo:
                logger.warning(f"RSS è§£æè­¦å‘Š: {username} - {feed.bozo_exception}")
            
            if hasattr(feed, 'entries') and len(feed.entries) > 0:
                logger.info(f"âœ… æˆåŠŸè·å– {len(feed.entries)} æ¡æ¨æ–‡: {username}")
                return feed
            
            logger.warning(f"âš ï¸ æ— æ¨æ–‡æ•°æ®: {username}")
            return None
            
        except Exception as e:
            logger.error(f"âŒ RSS è·å–å¤±è´¥: {username} - {e}")
            return None
    
    def _extract_strategy_content(self, content: str, keywords: List[str]) -> Optional[str]:
        """ä»æ¨æ–‡å†…å®¹ä¸­æå–ç­–ç•¥ç›¸å…³ä¿¡æ¯"""
        if not keywords:
            return content[:200] if content else None
        
        # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
        content_lower = content.lower()
        keywords_lower = [k.lower() for k in keywords]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç­–ç•¥å…³é”®è¯
        for keyword in keywords_lower:
            if keyword in content_lower:
                # æ‰¾åˆ°å…³é”®è¯ï¼Œè¿”å›åŒ…å«å…³é”®è¯çš„ä¸Šä¸‹æ–‡
                idx = content_lower.find(keyword)
                start = max(0, idx - 50)
                end = min(len(content), idx + 100)
                return content[start:end].strip()
        
        return None
    
    def _is_spam_or_promotion(self, content: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºåƒåœ¾å¹¿å‘Šæˆ–æ¨å¹¿å†…å®¹"""
        spam_patterns = [
            r'(?:DM|dm|ç§ä¿¡).*?(?:è·å–|get|é¢†å–)',
            r'(?:å…è´¹|free).*?(?:èµ é€|é¢†å–|åŠ å¾®ä¿¡)',
            r'(?:æƒç¢¼|æ‰«ç |ç‚¹å‡»é“¾æ¥)',
            r'(?:ä»£å¸|token).*?(?:å‘è¡Œ|launch|å‘å°„)',
            r'(?:ç©ºæŠ•|airdrop).*?(?:é¢†å–|claim)',
            r'https?://t\.co/\S+',  # çŸ­é“¾æ¥é€šå¸¸æ˜¯æ¨å¹¿
        ]
        
        for pattern in spam_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                return True
        
        return False
    
    def _is_retweet(self, content: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºè½¬å‘å†…å®¹"""
        rt_patterns = [
            r'^RT @',
            r'^è½¬å‘è‡ª',
            r'âš ï¸.*?è½¬å‘',
        ]
        
        for pattern in rt_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                return True
        
        return False
    
    def parse_tweets(self, username: str, feed: feedparser.FeedParserDict, strategy_keywords: List[str] = None) -> List[TweetItem]:
        """è§£ææ¨æ–‡å¹¶æå–ç­–ç•¥å†…å®¹"""
        tweets = []
        
        for entry in feed.entries[:10]:  # åªå–æœ€æ–°10æ¡
            # è·å–æ¨æ–‡å†…å®¹
            content = entry.get('summary', '') or entry.get('title', '')
            
            # è·³è¿‡è½¬å‘
            if self._is_retweet(content):
                continue
            
            # è·³è¿‡åƒåœ¾å¹¿å‘Š
            if self._is_spam_or_promotion(content):
                continue
            
            # æå–ç­–ç•¥å†…å®¹
            if strategy_keywords:
                strategy_content = self._extract_strategy_content(content, strategy_keywords)
                if not strategy_content:
                    continue  # æ²¡æœ‰ç­–ç•¥ç›¸å…³å†…å®¹ï¼Œè·³è¿‡
            else:
                strategy_content = content[:200]
            
            # è·å–å‘å¸ƒæ—¶é—´
            published = entry.get('published', datetime.now().isoformat())
            
            # ç”Ÿæˆé“¾æ¥
            link = entry.get('link', f'https://twitter.com/{username}/status/unknown')
            
            tweet = TweetItem(
                author=username,
                url=link,
                title=entry.get('title', content[:100]),
                content=content,
                published_at=published,
                source="rss"
            )
            
            tweets.append(tweet)
            logger.info(f"ğŸ“° è§£ææ¨æ–‡: {content[:50]}...")
        
        return tweets
    
    def scan_account(self, account: Dict) -> List[TweetItem]:
        """æ‰«æå•ä¸ªè´¦å·"""
        username = account.get('username')
        strategy_keywords = account.get('strategy_keywords', [])
        
        if not username:
            return []
        
        logger.info(f"\n{'='*50}")
        logger.info(f"ğŸ” RSS æ‰«æè´¦å·: @{username}")
        logger.info(f"ğŸ“Š ç­–ç•¥å…³é”®è¯: {strategy_keywords}")
        
        # æ£€æŸ¥ RSS æ˜¯å¦å¯ç”¨
        if not self.check_rss_available(username):
            logger.warning(f"âš ï¸ RSS ä¸å¯ç”¨ï¼Œè¿”å› None ä»¥ä¾¿ä½¿ç”¨ Playwright")
            return None  # è¿”å› None è¡¨ç¤ºéœ€è¦ä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
        
        # è·å– RSS æº
        feed = self.fetch_feed(username)
        if not feed:
            return None
        
        # è§£ææ¨æ–‡
        tweets = self.parse_tweets(username, feed, strategy_keywords)
        logger.info(f"âœ… è·å– {len(tweets)} æ¡ç­–ç•¥ç›¸å…³æ¨æ–‡")
        
        return tweets
    
    def scan_all(self) -> Dict[str, List[TweetItem]]:
        """æ‰«ææ‰€æœ‰é…ç½®è´¦å·ï¼ˆåªæ‰«æé…ç½®ä¸º RSS çš„è´¦å·ï¼‰"""
        results = {}
        
        for account in self.accounts:
            source = account.get('source', 'rss')
            
            if source != 'rss':
                logger.info(f"â­ï¸ è·³è¿‡é RSS è´¦å·: @{account.get('username')} (ä½¿ç”¨ {source})")
                continue
            
            username = account.get('username')
            tweets = self.scan_account(account)
            
            if tweets:
                results[username] = tweets
            elif tweets is None:
                # RSS ä¸å¯ç”¨ï¼Œè®°å½•ä½†ä¸è®©å®ƒå¤±è´¥
                results[username] = []
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    scanner = XRSSScanner()
    
    print("\n" + "="*60)
    print("ğŸ”” X/Twitter RSS æ‰«æå™¨")
    print("="*60)
    
    # æµ‹è¯• RSS å¯ç”¨æ€§
    for account in scanner.accounts:
        if account.get('source') == 'rss':
            username = account.get('username')
            available = scanner.check_rss_available(username)
            print(f"@{username}: {'âœ… RSS å¯ç”¨' if available else 'âŒ RSS ä¸å¯ç”¨'}")
    
    # æ‰§è¡Œæ‰«æ
    results = scanner.scan_all()
    
    print(f"\nğŸ“Š RSS æ‰«æç»“æœ:")
    total_tweets = sum(len(tweets) for tweets in results.values())
    print(f"   æ€»è´¦å·æ•°: {len([a for a in scanner.accounts if a.get('source') == 'rss'])}")
    print(f"   ç­–ç•¥æ¨æ–‡: {total_tweets}")

if __name__ == "__main__":
    main()
